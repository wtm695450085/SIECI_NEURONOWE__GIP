{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 220%;color:#1155cc\"> Pytorch: EMBEDDING #1 MS Tytanic  30.03.2021\n",
    "    \n",
    "<span style=\"font-size: 180%;color:red\"> 30.03.2021     \n",
    "\n",
    "Classification Example using a neural network with embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 30 08:40:52 2021\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time() ## pomiar czasu: start pomiaru czasu\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PassengerId  Survived  Pclass  \\\n",
       "0           0            1         0       3   \n",
       "1           1            2         1       1   \n",
       "2           2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/media/wojciech/D6DE33C1DE3399271/1A/kaggletrain.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8536626950>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.Survived.value_counts().plot(kind='pie', autopct='%1.0f%%', colors=['#45818e', '#f1c232'], explode=(0.05, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I check data completeness and delete records with empty NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       0\n",
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation of variables:  (891, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f85365b2650>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "print('Observation of variables: ',df.shape)\n",
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='BuPu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I delete several columns and empty records in Age columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['Cabin']\n",
    "del df['Ticket']\n",
    "del df['Name']\n",
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrangement of columns with categorical and continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Fare', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sex', 'Embarked'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[\"object\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[np.number]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_columns = ['Sex', 'Embarked']\n",
    "numerical_columns = ['PassengerId', 'Age', 'SibSp','Parch', 'Fare','Pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    519\n",
       "1    110\n",
       "2     68\n",
       "5      5\n",
       "3      5\n",
       "4      4\n",
       "6      1\n",
       "Name: Parch, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We determine that the output variable is the 'Stroke' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digitization of text variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Fare           float64\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert types for qualitative columns to category. We can do this using the astype () function, as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Introducing a new data type: 'category'</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categorical_columns:\n",
    "    df[category] = df[category].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       int64\n",
       "Survived          int64\n",
       "Pclass            int64\n",
       "Sex            category\n",
       "Age             float64\n",
       "SibSp             int64\n",
       "Parch             int64\n",
       "Fare            float64\n",
       "Embarked       category\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['female', 'male'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['C', 'Q', 'S'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Embarked'].cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digitization of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       int64\n",
       "Survived          int64\n",
       "Pclass            int64\n",
       "Sex            category\n",
       "Age             float64\n",
       "SibSp             int64\n",
       "Parch             int64\n",
       "Fare            float64\n",
       "Embarked       category\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why did we digitize data in the format?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic purpose of separating categorical columns from numeric columns is that the values in the numeric column can be directly input into neural networks. However, categorized column values must first be converted to numeric types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex', 'Embarked']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of categorical variables to Numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [0, 0],\n",
       "       [0, 2],\n",
       "       [0, 2],\n",
       "       [1, 2],\n",
       "       [1, 2],\n",
       "       [1, 2],\n",
       "       [0, 2],\n",
       "       [0, 0],\n",
       "       [0, 2]], dtype=int8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = df['Sex'].cat.codes.values\n",
    "p2 = df['Embarked'].cat.codes.values\n",
    "\n",
    "\n",
    "NumP_matrix = np.stack([p1, p2], 1)\n",
    "\n",
    "NumP_matrix[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odpalam karte graficzną GPU"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#device = torch.device('cpu') # obliczenia robie na CPU\n",
    "device = torch.device('cuda') # obliczenia robie na GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Pytorch tensor from the Numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [0, 0],\n",
       "        [0, 2],\n",
       "        [0, 2],\n",
       "        [1, 2],\n",
       "        [1, 2],\n",
       "        [1, 2],\n",
       "        [0, 2],\n",
       "        [0, 0],\n",
       "        [0, 2]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_data = torch.tensor(NumP_matrix, dtype=torch.int64, device=device)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of DataFrame numeric columns to a Pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, 22.0000,  1.0000,  0.0000,  7.2500,  3.0000],\n",
       "        [ 2.0000, 38.0000,  1.0000,  0.0000, 71.2833,  1.0000],\n",
       "        [ 3.0000, 26.0000,  0.0000,  0.0000,  7.9250,  3.0000],\n",
       "        [ 4.0000, 35.0000,  1.0000,  0.0000, 53.1000,  1.0000],\n",
       "        [ 5.0000, 35.0000,  0.0000,  0.0000,  8.0500,  3.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_data = np.stack([df[col].values for col in numerical_columns], 1)\n",
    "numerical_data = torch.tensor(numerical_data, dtype=torch.float, device=device)\n",
    "numerical_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert result variables to the Pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wojciech/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = torch.tensor(df[outputs].values).flatten()\n",
    "outputs = torch.tensor(outputs, device=device)\n",
    "outputs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's sum up the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_data:  torch.Size([712, 2])\n",
      "numerical_data:    torch.Size([712, 6])\n",
      "outputs:           torch.Size([712])\n"
     ]
    }
   ],
   "source": [
    "print('categorical_data: ',categorical_data.shape)\n",
    "print('numerical_data:   ',numerical_data.shape)\n",
    "print('outputs:          ',outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">settlement</span>\n",
    "Przekształciliśmy nasze kolumny kategorialne na liczbowe, w których unikalną wartość reprezentuje jedna liczba całkowita (cyfryzacja - np. Palacz to 1). Na podstawie takiej kolumny (zmiennej) możemy trenować model, ale jest lepszy sposób ...\n",
    "\n",
    "Lepszym sposobem jest przedstawienie wartości w kolumnie jakościowej jako N-wymiarowego wektora zamiast pojedynczej liczby całkowitej. Ten proces nazywa się osadzaniem. Wektor jest w stanie uchwycić więcej informacji i może znaleźć relacje między różnymi wartościami kategorialnymi w bardziej odpowiedni sposób. Dlatego będziemy przedstawiać wartości w kolumnach kategorialnych w postaci wektorów N-wymiarowych.\n",
    "\n",
    "Musimy zdefiniować rozmiar osadzania (wymiary wektora) dla wszystkich kolumn jakościowych. Nie ma sztywnej zasady dotyczącej liczby wymiarów. Dobrą zasadą definiowania rozmiaru osadzania dla kolumny jest podzielenie liczby unikalnych wartości w kolumnie przez 2 (ale nie więcej niż 50).\n",
    "\n",
    "Poniższy skrypt tworzy krotkę zawierającą liczbę unikalnych wartości i rozmiary wymiarów dla wszystkich kolumn jakościowych (dyskretnych).\n",
    "\n",
    "Zasada jest prosta: matryca osadzająca musi zawsze znajdować się w liczbie wierszy większej niż zakres zmiennych w liczbie wierszy: dlatego dodałem col_size + 2, to duży zapas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 3), (5, 4)]\n"
     ]
    }
   ],
   "source": [
    "categorical_column_sizes = [len(df[column].cat.categories) for column in categorical_columns]\n",
    "categorical_embedding_sizes = [(col_size+2, min(50, (col_size+5)//2)) for col_size in categorical_column_sizes]\n",
    "print(categorical_embedding_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dzielenie zestawu na szkoleniowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_records = df['Age'].count()\n",
    "test_records = int(total_records * .2)\n",
    "\n",
    "categorical_train_data = categorical_data[:total_records-test_records]\n",
    "categorical_test_data = categorical_data[total_records-test_records:total_records]\n",
    "numerical_train_data = numerical_data[:total_records-test_records]\n",
    "numerical_test_data = numerical_data[total_records-test_records:total_records]\n",
    "train_outputs = outputs[:total_records-test_records]\n",
    "test_outputs = outputs[total_records-test_records:total_records]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby sprawdzić, czy poprawnie podzieliliśmy dane na zestawy treningów i testów, wydrukujmy długości rekordów szkolenia i testów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_train_data:  torch.Size([570, 2])\n",
      "numerical_train_data:    torch.Size([570, 6])\n",
      "train_outputs:           torch.Size([570])\n",
      "----------------------------------------------------\n",
      "categorical_test_data:   torch.Size([142, 2])\n",
      "numerical_test_data:     torch.Size([142, 6])\n",
      "test_outputs:            torch.Size([142])\n"
     ]
    }
   ],
   "source": [
    "print('categorical_train_data: ',categorical_train_data.shape)\n",
    "print('numerical_train_data:   ',numerical_train_data.shape)\n",
    "print('train_outputs:          ', train_outputs.shape)\n",
    "print('----------------------------------------------------')\n",
    "print('categorical_test_data:  ',categorical_test_data.shape)\n",
    "print('numerical_test_data:    ',numerical_test_data.shape)\n",
    "print('test_outputs:           ',test_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzam czy wszędzie są CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_train_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, 22.0000,  1.0000,  0.0000,  7.2500,  3.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_train_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outputs[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_test_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[720.0000,  33.0000,   0.0000,   0.0000,   7.7750,   3.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_test_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_outputs[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 130%;color:#1155cc\"> Model sieci neuronwej (rozbudowany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size, num_numerical_cols, output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "        self.batch_norm_num = nn.BatchNorm1d(num_numerical_cols)\n",
    "\n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols + num_numerical_cols\n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, x_categorical, x_numerical):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "\n",
    "        x_numerical = self.batch_norm_num(x_numerical)\n",
    "        x = torch.cat([x, x_numerical], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_embedding_sizes:   [(4, 3), (5, 4)]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print('categorical_embedding_sizes:  ',categorical_embedding_sizes)\n",
    "print(numerical_data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deklaruje model jako CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(categorical_embedding_sizes, numerical_data.shape[1], 2, [200,100,50], p=0.4).to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = FeedForwardNN(emb_dims, no_of_cont=4, lin_layer_sizes=[50, 100],\n",
    "                          output_size=1, emb_dropout=0.04,\n",
    "                          lin_layer_dropouts=[0.001,0.01]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0): Embedding(4, 3)\n",
      "    (1): Embedding(5, 4)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (batch_norm_num): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=13, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "    (12): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 130%;color:#1155cc\"> Funkcja straty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "#loss_function = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 130%;color:#1155cc\"> Optymalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.Rprop(model.parameters(), lr=0.001, etas=(0.5, 1.2), step_sizes=(1e-06, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_embedding_sizes:   [(4, 3), (5, 4)]\n",
      "6\n",
      "categorical_train_data:  torch.Size([570, 2])\n",
      "numerical_train_data:    torch.Size([570, 6])\n",
      "outputs:                 torch.Size([570])\n"
     ]
    }
   ],
   "source": [
    "print('categorical_embedding_sizes:  ',categorical_embedding_sizes)\n",
    "print(numerical_data.shape[1])\n",
    "print('categorical_train_data: ',categorical_train_data.shape)\n",
    "print('numerical_train_data:   ',numerical_train_data.shape)\n",
    "print('outputs:                ',train_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(categorical_train_data, numerical_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 0.77197081\n",
      "epoch:  51 loss: 0.42693827\n",
      "epoch: 101 loss: 0.36592701\n",
      "epoch: 151 loss: 0.35305533\n",
      "epoch: 201 loss: 0.30417338\n",
      "epoch: 251 loss: 0.32060677\n",
      "epoch: 301 loss: 0.29156220\n",
      "epoch: 351 loss: 0.27491406\n",
      "epoch: 401 loss: 0.24462500\n",
      "epoch: 451 loss: 0.24685991\n",
      "epoch: 501 loss: 0.25024986\n",
      "epoch: 551 loss: 0.25293887\n",
      "epoch: 601 loss: 0.23391744\n",
      "epoch: 651 loss: 0.23859097\n",
      "epoch: 701 loss: 0.23928618\n",
      "epoch: 751 loss: 0.19122434\n",
      "epoch: 801 loss: 0.23691390\n",
      "epoch: 851 loss: 0.20809686\n",
      "epoch: 901 loss: 0.22809809\n",
      "epoch: 951 loss: 0.19380800\n",
      "epoch: 1001 loss: 0.18346217\n",
      "epoch: 1051 loss: 0.23789167\n",
      "epoch: 1101 loss: 0.21251588\n",
      "epoch: 1151 loss: 0.16233148\n",
      "epoch: 1201 loss: 0.17943303\n",
      "epoch: 1251 loss: 0.18259396\n",
      "epoch: 1301 loss: 0.17894670\n",
      "epoch: 1351 loss: 0.18110210\n",
      "epoch: 1401 loss: 0.18292369\n",
      "epoch: 1451 loss: 0.18924515\n",
      "epoch: 1501 loss: 0.13720286\n",
      "epoch: 1551 loss: 0.18210106\n",
      "epoch: 1601 loss: 0.15823077\n",
      "epoch: 1651 loss: 0.18245934\n",
      "epoch: 1701 loss: 0.17985857\n",
      "epoch: 1751 loss: 0.17807920\n",
      "epoch: 1801 loss: 0.15766157\n",
      "epoch: 1851 loss: 0.12750752\n",
      "epoch: 1901 loss: 0.17561942\n",
      "epoch: 1951 loss: 0.13213830\n",
      "epoch: 2001 loss: 0.14378037\n",
      "epoch: 2051 loss: 0.13135463\n",
      "epoch: 2101 loss: 0.16750890\n",
      "epoch: 2151 loss: 0.16503365\n",
      "epoch: 2201 loss: 0.15043570\n",
      "epoch: 2251 loss: 0.13482553\n",
      "epoch: 2301 loss: 0.14343037\n",
      "epoch: 2351 loss: 0.19105752\n",
      "epoch: 2401 loss: 0.14377733\n",
      "epoch: 2451 loss: 0.13792914\n",
      "epoch: 2501 loss: 0.13233913\n",
      "epoch: 2551 loss: 0.13632393\n",
      "epoch: 2601 loss: 0.13158065\n",
      "epoch: 2651 loss: 0.10768150\n",
      "epoch: 2701 loss: 0.15747336\n",
      "epoch: 2751 loss: 0.13777882\n",
      "epoch: 2801 loss: 0.11552893\n",
      "epoch: 2851 loss: 0.11705194\n",
      "epoch: 2901 loss: 0.13326651\n",
      "epoch: 2951 loss: 0.10374778\n",
      "epoch: 3001 loss: 0.12510942\n",
      "epoch: 3051 loss: 0.14734679\n",
      "epoch: 3101 loss: 0.14531307\n",
      "epoch: 3151 loss: 0.11511058\n",
      "epoch: 3201 loss: 0.11553333\n",
      "epoch: 3251 loss: 0.11731387\n",
      "epoch: 3301 loss: 0.11092836\n",
      "epoch: 3351 loss: 0.11624537\n",
      "epoch: 3401 loss: 0.15714395\n",
      "epoch: 3451 loss: 0.16988195\n",
      "epoch: 3501 loss: 0.12422251\n",
      "epoch: 3551 loss: 0.15033577\n",
      "epoch: 3601 loss: 0.10499722\n",
      "epoch: 3651 loss: 0.14551485\n",
      "epoch: 3701 loss: 0.11364331\n",
      "epoch: 3751 loss: 0.14712222\n",
      "epoch: 3801 loss: 0.12999047\n",
      "epoch: 3851 loss: 0.09424891\n",
      "epoch: 3901 loss: 0.07802974\n",
      "epoch: 3951 loss: 0.12606455\n",
      "epoch: 4001 loss: 0.11057349\n",
      "epoch: 4051 loss: 0.12924647\n",
      "epoch: 4101 loss: 0.09824837\n",
      "epoch: 4151 loss: 0.13136803\n",
      "epoch: 4201 loss: 0.12020919\n",
      "epoch: 4251 loss: 0.09218580\n",
      "epoch: 4301 loss: 0.12518954\n",
      "epoch: 4351 loss: 0.12130727\n",
      "epoch: 4401 loss: 0.09956749\n",
      "epoch: 4451 loss: 0.09480618\n",
      "epoch: 4501 loss: 0.13074741\n",
      "epoch: 4551 loss: 0.11240850\n",
      "epoch: 4600 loss: 0.0916322023\n"
     ]
    }
   ],
   "source": [
    "epochs = 4600\n",
    "aggregated_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model(categorical_train_data, numerical_train_data)\n",
    "    \n",
    "    single_loss = loss_function(y_pred, train_outputs)\n",
    "    aggregated_losses.append(single_loss)\n",
    "\n",
    "    if i%50 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), aggregated_losses, color='r')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast based on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train_set: 0.09116735\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_val_train = model(categorical_train_data, numerical_train_data)\n",
    "    loss = loss_function( y_val_train, train_outputs)\n",
    "print(f'Loss train_set: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.88942242\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_val = model(categorical_test_data, numerical_test_data)\n",
    "    loss = loss_function(y_val, test_outputs)\n",
    "print(f'Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NIE POWINNO SIĘ PORÓWNYWAĆ y_val (wynik modelu), KTÓRY MA format ZMIENNYCH FLOAD do test_outputs który ma format zero-jedynkowy. \n",
    "\n",
    "Ponieważ ustaliliśmy, że nasza warstwa wyjściowa będzie zawierała 2 neurony, każda prognoza będzie zawierała 2 wartości. Na przykład pierwsze 5 przewidywanych wartości to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(test_outputs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.6996, -6.2861],\n",
      "        [-4.2501,  3.6216],\n",
      "        [ 2.8857, -2.8821],\n",
      "        [ 0.2375, -0.4227],\n",
      "        [ 0.8386, -0.9932]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZMIANA FORMATU WYNIKÓW Z FORMATU FLOAT NA FORMAT BINARNY\n",
    "\n",
    "Celem takich prognoz jest to, że jeśli faktyczny wynik wynosi 0, wartość wskaźnika 0 powinna być wyższa niż wartość wskaźnika 1 i odwrotnie. Możemy uzyskać największy indeks wartości z listy za pomocą następującego skryptu:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 180%;color:#1155cc\"> Najpier kopiuje tensor y_val z CUDA do CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.6996, -6.2861]], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = y_val.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyższe równanie zwraca maksymalne wskaźniki wartości wzdłuż osi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_val[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ na liście pierwotnie przewidywanych wyników dla pierwszych pięciu rekordów wartości indeksów zerowych są większe niż wartości w pierwszych indeksach, możemy zobaczyć 0 w pierwszych pięciu wierszach przetworzonych danych wyjściowych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 180%;color:#1155cc\"> Kopiujemy tensor 'test_outputs' z CUDA do CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = test_outputs.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 180%;color:#1155cc\"> Sprawdzamy jaki jest poziom klasyfikacji modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65 22]\n",
      " [17 38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77        87\n",
      "           1       0.63      0.69      0.66        55\n",
      "\n",
      "    accuracy                           0.73       142\n",
      "   macro avg       0.71      0.72      0.72       142\n",
      "weighted avg       0.73      0.73      0.73       142\n",
      "\n",
      "accuracy_score: 0.7253521126760564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(test_outputs,y_val))\n",
    "print(classification_report(test_outputs,y_val))\n",
    "print('accuracy_score:',accuracy_score(test_outputs, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 150%;background:#ffd966\">We save the whole model</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wojciech/anaconda3/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model,'/home/wojciech/Pulpit/3/byk2.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 150%;background:#ffd966\"> We play the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (all_embeddings): ModuleList(\n",
       "    (0): Embedding(4, 3)\n",
       "    (1): Embedding(5, 4)\n",
       "  )\n",
       "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
       "  (batch_norm_num): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=13, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Dropout(p=0.4, inplace=False)\n",
       "    (12): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KOT = torch.load('/home/wojciech/Pulpit/3/byk2.pb')\n",
    "KOT.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 190%;background:#d9ead3\"> Podstawiając inne zmienne niezależne, można uzyskać wektor zmiennych wyjściowych\n",
    "\n",
    "Bierzemy co 5 wartość z wyminiononych zmiennych - to będą nasze zmienne do podstawienia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [1, 2],\n",
       "        [0, 2],\n",
       "        [1, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = categorical_train_data[::5]\n",
    "A[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, 22.0000,  1.0000,  0.0000,  7.2500,  3.0000],\n",
       "        [ 7.0000, 54.0000,  0.0000,  0.0000, 51.8625,  1.0000],\n",
       "        [12.0000, 58.0000,  0.0000,  0.0000, 26.5500,  1.0000],\n",
       "        [17.0000,  2.0000,  4.0000,  1.0000, 29.1250,  3.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = numerical_train_data[::5]\n",
    "B[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =train_outputs[::5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 190%;background:#d9ead3\"> Teraz podstawiamy te wartości do wybanego modelu KOT\n",
    "    \n",
    "    wynik modelu to y_pred_AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.1658, -3.5893],\n",
       "        [ 3.7047, -4.1171],\n",
       "        [-8.3789,  8.4208],\n",
       "        [ 6.4681, -7.0089],\n",
       "        [-9.4584,  9.8115],\n",
       "        [ 4.1367, -4.5161],\n",
       "        [-3.7881,  3.6547],\n",
       "        [ 3.3073, -3.7599],\n",
       "        [ 5.8718, -6.1053],\n",
       "        [ 3.3297, -3.2451]], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_AB = KOT(A, B)\n",
    "y_pred_AB[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss train_set: 0.04674229\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_val_AB = KOT(A,B)\n",
    "    loss = loss_function( y_val_AB, y)\n",
    "print(f'Loss train_set: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "przerabiamy z CUDA na CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_AB = y_val_AB.cpu().data.numpy()\n",
    "y = y.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_AB = np.argmax(y_val_AB, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  2]\n",
      " [ 1 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98        67\n",
      "           1       0.96      0.98      0.97        47\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y,y_val_AB))\n",
    "print(classification_report(y,y_val_AB))\n",
    "print(accuracy_score(y, y_val_AB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring the time to complete this task:\n",
      "0.45191969474156696\n"
     ]
    }
   ],
   "source": [
    "print('Measuring the time to complete this task:')\n",
    "print((time.time() - start_time)/60) ## koniec pomiaru czasu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
