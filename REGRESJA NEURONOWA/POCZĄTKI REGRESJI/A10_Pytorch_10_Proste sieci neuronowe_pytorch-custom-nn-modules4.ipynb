{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 220%;color:#1155cc\">  Pytorch_10_Proste sieci neuronowe_pytorch-custom-nn-modules4\n",
    "\n",
    "<span style=\"font-size: 180%;color:red\"> 17.09.2020   \n",
    "\n",
    "W PyTorch <span style=\"font-size: 100%;color:red\">nnpakiet</span> określa zestaw modułów , które są w przybliżeniu równoważne dla warstwy sieci neuronowych. Moduł odbiera Tensory wejściowe i oblicza Tensory wyjściowe, ale może również utrzymywać stan wewnętrzny, taki jak Tensory zawierające parametry możliwe do nauczenia. nnPakiet definiuje także zestaw przydatnych funkcji straty, które są powszechnie stosowane podczas treningu sieci neuronowych.\n",
    "\n",
    "https://github.com/jcjohnson/pytorch-examples#pytorch-custom-nn-modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Odpalam karte graficzną GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cpu') # obliczenia robie na CPU\n",
    "device = torch.device('cuda') # obliczenia robie na GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane\n",
    "- N to wielkość partii (ilośc rekordów, wielkość próbki); \n",
    "- D_in jest wymiarem wejściowym (liczba zmiennych opisujących); \n",
    "- H jest ukrytym wymiarem (ukryta warstwa); \n",
    "- D_out jest wymiarem wyjściowym(ilość zmiennych wynikowych). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyżej zostały określone parametry aby tensor zmiennych niezależnych i tensor wynikowy były odpowiednie \n",
    "\n",
    "x: 64 obserwacji i 1000 zmiennych\n",
    "\n",
    "y: 64 obserwacji i 10 zmiennych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tworzy losowe dane wejściowe i wyjściowe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 130%;color:#1155cc\"> Model sieci neuronwej\n",
    "    \n",
    "Użyj<span style=\"font-size: 120%;color:red\"> pakietu nn</span>, aby zdefiniować nasz model jako sekwencję warstw. nn.Sequential to moduł, który zawiera inne moduły i stosuje je kolejno, aby wygenerowały wynik. Każdy moduł liniowy oblicza dane wyjściowe za pomocą funkcji liniowej i przechowuje wewnętrzne tensory ze względu na swoją wagę i obciążenie. Po zbudowaniu modelu używamy metody .to (), aby przenieść go na żądane urządzenie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "          torch.nn.Linear(D_in, H),\n",
    "          torch.nn.ReLU(),\n",
    "          torch.nn.Linear(H, D_out),\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 130%;color:#1155cc\"> Funkcja straty MSE\n",
    "    \n",
    "<span style=\"font-size: 120%;color:red\"> Pakiet nn</span> zawiera również definicje popularnych funkcji utraty; w tym wypadku użyjemy błąd średniokwadratowy (MSE) w naszej funkcji strat. Ustawienie redukcji = „suma” oznacza, że obliczamy * sumę * błędów kwadratu; ma to na celu zachowanie spójności z powyższymi przykładami, w których ręcznie obliczamy stratę, ale w praktyce bardziej powszechne jest stosowanie średniego kwadratu błędu jako straty, ustawiając redukcję = „elementwise_mean”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definiowanie nauki\n",
    "Przekaz do przodu: oblicz przewidywane y przez przekazanie x do modelu. Obiekty modułowe \n",
    "przesłania operator __call__, aby można było wywoływać je jak funkcje. Gdy w ten sposób przekazujesz Tensor danych wejściowych do modułu i on generuje tensor danych wyjściowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 685.885498046875\n",
      "1 633.3931884765625\n",
      "2 588.0958251953125\n",
      "3 548.495361328125\n",
      "4 513.56591796875\n",
      "5 482.33392333984375\n",
      "6 454.00927734375\n",
      "7 428.2730712890625\n",
      "8 404.52325439453125\n",
      "9 382.40740966796875\n",
      "10 361.7473449707031\n",
      "11 342.5929260253906\n",
      "12 324.5709228515625\n",
      "13 307.5721435546875\n",
      "14 291.4803466796875\n",
      "15 276.1668701171875\n",
      "16 261.6961669921875\n",
      "17 247.91555786132812\n",
      "18 234.82847595214844\n",
      "19 222.34661865234375\n",
      "20 210.44381713867188\n",
      "21 199.11495971679688\n",
      "22 188.28453063964844\n",
      "23 177.95181274414062\n",
      "24 168.08621215820312\n",
      "25 158.67880249023438\n",
      "26 149.72474670410156\n",
      "27 141.20431518554688\n",
      "28 133.08895874023438\n",
      "29 125.37235260009766\n",
      "30 118.04200744628906\n",
      "31 111.08650207519531\n",
      "32 104.50129699707031\n",
      "33 98.26167297363281\n",
      "34 92.35977935791016\n",
      "35 86.7965087890625\n",
      "36 81.5539779663086\n",
      "37 76.61553955078125\n",
      "38 71.96519470214844\n",
      "39 67.57984161376953\n",
      "40 63.45069122314453\n",
      "41 59.56219482421875\n",
      "42 55.912540435791016\n",
      "43 52.48992919921875\n",
      "44 49.269569396972656\n",
      "45 46.24784851074219\n",
      "46 43.41759490966797\n",
      "47 40.76548385620117\n",
      "48 38.27946472167969\n",
      "49 35.95233154296875\n",
      "50 33.769962310791016\n",
      "51 31.723278045654297\n",
      "52 29.808624267578125\n",
      "53 28.01384162902832\n",
      "54 26.329647064208984\n",
      "55 24.753002166748047\n",
      "56 23.280275344848633\n",
      "57 21.902029037475586\n",
      "58 20.61281967163086\n",
      "59 19.407207489013672\n",
      "60 18.278263092041016\n",
      "61 17.218643188476562\n",
      "62 16.226158142089844\n",
      "63 15.296846389770508\n",
      "64 14.42223072052002\n",
      "65 13.601812362670898\n",
      "66 12.833568572998047\n",
      "67 12.113913536071777\n",
      "68 11.439221382141113\n",
      "69 10.805524826049805\n",
      "70 10.210639953613281\n",
      "71 9.65223503112793\n",
      "72 9.127923011779785\n",
      "73 8.634875297546387\n",
      "74 8.171452522277832\n",
      "75 7.737010955810547\n",
      "76 7.327275276184082\n",
      "77 6.9415059089660645\n",
      "78 6.578724384307861\n",
      "79 6.2369513511657715\n",
      "80 5.9152631759643555\n",
      "81 5.611888408660889\n",
      "82 5.326020240783691\n",
      "83 5.057061195373535\n",
      "84 4.803142070770264\n",
      "85 4.563690662384033\n",
      "86 4.337614059448242\n",
      "87 4.1239333152771\n",
      "88 3.9213154315948486\n",
      "89 3.730173110961914\n",
      "90 3.549863338470459\n",
      "91 3.379211902618408\n",
      "92 3.2177205085754395\n",
      "93 3.064768075942993\n",
      "94 2.9202017784118652\n",
      "95 2.7835030555725098\n",
      "96 2.6540122032165527\n",
      "97 2.531383752822876\n",
      "98 2.4150290489196777\n",
      "99 2.3048095703125\n",
      "100 2.200105667114258\n",
      "101 2.1008167266845703\n",
      "102 2.00667667388916\n",
      "103 1.917262077331543\n",
      "104 1.8323640823364258\n",
      "105 1.7509262561798096\n",
      "106 1.673589825630188\n",
      "107 1.6000545024871826\n",
      "108 1.5300416946411133\n",
      "109 1.463456153869629\n",
      "110 1.4001555442810059\n",
      "111 1.339824914932251\n",
      "112 1.2822980880737305\n",
      "113 1.2274867296218872\n",
      "114 1.1752893924713135\n",
      "115 1.1255556344985962\n",
      "116 1.0781341791152954\n",
      "117 1.0328729152679443\n",
      "118 0.9897247552871704\n",
      "119 0.948635995388031\n",
      "120 0.9095579385757446\n",
      "121 0.872241735458374\n",
      "122 0.8366341590881348\n",
      "123 0.802610456943512\n",
      "124 0.770106852054596\n",
      "125 0.7391365766525269\n",
      "126 0.7095213532447815\n",
      "127 0.6812072396278381\n",
      "128 0.6541953086853027\n",
      "129 0.6283600330352783\n",
      "130 0.6036174893379211\n",
      "131 0.5799746513366699\n",
      "132 0.557350754737854\n",
      "133 0.5356866121292114\n",
      "134 0.5149521827697754\n",
      "135 0.4951115548610687\n",
      "136 0.47608304023742676\n",
      "137 0.4578850567340851\n",
      "138 0.4404481053352356\n",
      "139 0.42372024059295654\n",
      "140 0.40771716833114624\n",
      "141 0.3923640847206116\n",
      "142 0.3776420056819916\n",
      "143 0.36351555585861206\n",
      "144 0.34994909167289734\n",
      "145 0.33692866563796997\n",
      "146 0.324448823928833\n",
      "147 0.31246697902679443\n",
      "148 0.300962895154953\n",
      "149 0.2899276614189148\n",
      "150 0.2793228328227997\n",
      "151 0.2691428065299988\n",
      "152 0.259372353553772\n",
      "153 0.24998754262924194\n",
      "154 0.24097275733947754\n",
      "155 0.23230880498886108\n",
      "156 0.22398684918880463\n",
      "157 0.2159741073846817\n",
      "158 0.20826877653598785\n",
      "159 0.20086076855659485\n",
      "160 0.19373564422130585\n",
      "161 0.18687644600868225\n",
      "162 0.1802789866924286\n",
      "163 0.17393262684345245\n",
      "164 0.16782601177692413\n",
      "165 0.16194769740104675\n",
      "166 0.15629056096076965\n",
      "167 0.15085524320602417\n",
      "168 0.1456194519996643\n",
      "169 0.1405790150165558\n",
      "170 0.13572847843170166\n",
      "171 0.13105449080467224\n",
      "172 0.12655223906040192\n",
      "173 0.12221841514110565\n",
      "174 0.11803682148456573\n",
      "175 0.1140071302652359\n",
      "176 0.11012506484985352\n",
      "177 0.10638211667537689\n",
      "178 0.10277950763702393\n",
      "179 0.0993061363697052\n",
      "180 0.09595519304275513\n",
      "181 0.09272326529026031\n",
      "182 0.08960683643817902\n",
      "183 0.08660250902175903\n",
      "184 0.08370600640773773\n",
      "185 0.08091065287590027\n",
      "186 0.07821350544691086\n",
      "187 0.07561373710632324\n",
      "188 0.07310488075017929\n",
      "189 0.07067815214395523\n",
      "190 0.0683395192027092\n",
      "191 0.0660812258720398\n",
      "192 0.06390127539634705\n",
      "193 0.061799824237823486\n",
      "194 0.059768736362457275\n",
      "195 0.05780867487192154\n",
      "196 0.055916402488946915\n",
      "197 0.05408954992890358\n",
      "198 0.05232568830251694\n",
      "199 0.050622791051864624\n",
      "200 0.048978596925735474\n",
      "201 0.0473889485001564\n",
      "202 0.04585293307900429\n",
      "203 0.044371601194143295\n",
      "204 0.042939066886901855\n",
      "205 0.04155493527650833\n",
      "206 0.040217138826847076\n",
      "207 0.03892455995082855\n",
      "208 0.037675514817237854\n",
      "209 0.036468178033828735\n",
      "210 0.03530179709196091\n",
      "211 0.03417399525642395\n",
      "212 0.03308471292257309\n",
      "213 0.03203113377094269\n",
      "214 0.031013084575533867\n",
      "215 0.03002869337797165\n",
      "216 0.02907652221620083\n",
      "217 0.02815607562661171\n",
      "218 0.02726595103740692\n",
      "219 0.02640577405691147\n",
      "220 0.025573354214429855\n",
      "221 0.024768497794866562\n",
      "222 0.023989947512745857\n",
      "223 0.023237306624650955\n",
      "224 0.022509193047881126\n",
      "225 0.021804507821798325\n",
      "226 0.021123051643371582\n",
      "227 0.02046353369951248\n",
      "228 0.019825588911771774\n",
      "229 0.019207647070288658\n",
      "230 0.01861005648970604\n",
      "231 0.018032236024737358\n",
      "232 0.017472803592681885\n",
      "233 0.01693122088909149\n",
      "234 0.016407184302806854\n",
      "235 0.015899576246738434\n",
      "236 0.015408418141305447\n",
      "237 0.01493337843567133\n",
      "238 0.014473563060164452\n",
      "239 0.014028596691787243\n",
      "240 0.013597695156931877\n",
      "241 0.013180430047214031\n",
      "242 0.012776552699506283\n",
      "243 0.012385187670588493\n",
      "244 0.012006537988781929\n",
      "245 0.011639638803899288\n",
      "246 0.011284522712230682\n",
      "247 0.010940533131361008\n",
      "248 0.010607440024614334\n",
      "249 0.010285213589668274\n",
      "250 0.0099728899076581\n",
      "251 0.009670061990618706\n",
      "252 0.00937667302787304\n",
      "253 0.009092487394809723\n",
      "254 0.008817337453365326\n",
      "255 0.00855078175663948\n",
      "256 0.008292659185826778\n",
      "257 0.008042600005865097\n",
      "258 0.00780028710141778\n",
      "259 0.007565459236502647\n",
      "260 0.007337827235460281\n",
      "261 0.007117287255823612\n",
      "262 0.006903602741658688\n",
      "263 0.006696509197354317\n",
      "264 0.006495822221040726\n",
      "265 0.006301400251686573\n",
      "266 0.006112972274422646\n",
      "267 0.00593033479526639\n",
      "268 0.005753169301897287\n",
      "269 0.005581507459282875\n",
      "270 0.005415232852101326\n",
      "271 0.005254019051790237\n",
      "272 0.00509753217920661\n",
      "273 0.0049459971487522125\n",
      "274 0.004799087531864643\n",
      "275 0.004656546283513308\n",
      "276 0.004518404137343168\n",
      "277 0.004384458996355534\n",
      "278 0.004254672210663557\n",
      "279 0.004128676373511553\n",
      "280 0.004006546922028065\n",
      "281 0.003888144623488188\n",
      "282 0.0037733400240540504\n",
      "283 0.0036620942410081625\n",
      "284 0.003554082475602627\n",
      "285 0.0034493913408368826\n",
      "286 0.00334783922880888\n",
      "287 0.003249351866543293\n",
      "288 0.0031538126058876514\n",
      "289 0.0030612023547291756\n",
      "290 0.002971348352730274\n",
      "291 0.0028841921593993902\n",
      "292 0.0027996590360999107\n",
      "293 0.0027176705189049244\n",
      "294 0.002638177014887333\n",
      "295 0.00256103347055614\n",
      "296 0.0024861793499439955\n",
      "297 0.0024135701823979616\n",
      "298 0.0023431829176843166\n",
      "299 0.0022748333867639303\n",
      "300 0.0022085271775722504\n",
      "301 0.002144171390682459\n",
      "302 0.00208180770277977\n",
      "303 0.0020212773233652115\n",
      "304 0.001962516689673066\n",
      "305 0.0019055083394050598\n",
      "306 0.001850234461016953\n",
      "307 0.001796566997654736\n",
      "308 0.0017444930272176862\n",
      "309 0.0016939459601417184\n",
      "310 0.001644897274672985\n",
      "311 0.0015972934197634459\n",
      "312 0.0015511077363044024\n",
      "313 0.001506265951320529\n",
      "314 0.0014627774944528937\n",
      "315 0.0014205803163349628\n",
      "316 0.001379645662382245\n",
      "317 0.0013398798182606697\n",
      "318 0.001301268581300974\n",
      "319 0.001263775397092104\n",
      "320 0.0012273956090211868\n",
      "321 0.0011921090772375464\n",
      "322 0.0011578449048101902\n",
      "323 0.0011246013455092907\n",
      "324 0.0010923183290287852\n",
      "325 0.0010609780438244343\n",
      "326 0.0010305565083399415\n",
      "327 0.0010010194964706898\n",
      "328 0.0009723312105052173\n",
      "329 0.0009444926399737597\n",
      "330 0.0009174517472274601\n",
      "331 0.0008912234334275126\n",
      "332 0.0008657648577354848\n",
      "333 0.0008410217706114054\n",
      "334 0.0008170142536982894\n",
      "335 0.0007936526089906693\n",
      "336 0.0007709817728027701\n",
      "337 0.0007489649578928947\n",
      "338 0.0007275821408256888\n",
      "339 0.0007068137056194246\n",
      "340 0.0006866594776511192\n",
      "341 0.0006670912262052298\n",
      "342 0.0006480913143604994\n",
      "343 0.000629634247161448\n",
      "344 0.0006117112352512777\n",
      "345 0.0005943132564425468\n",
      "346 0.0005774134770035744\n",
      "347 0.0005610166699625552\n",
      "348 0.0005450901808217168\n",
      "349 0.0005296207964420319\n",
      "350 0.0005145908799022436\n",
      "351 0.0005000014789402485\n",
      "352 0.0004858251486439258\n",
      "353 0.0004720705619547516\n",
      "354 0.00045870820758864284\n",
      "355 0.0004457214963622391\n",
      "356 0.0004331132513470948\n",
      "357 0.00042086420580744743\n",
      "358 0.0004089767171535641\n",
      "359 0.0003974278806708753\n",
      "360 0.00038620296982116997\n",
      "361 0.0003753203200176358\n",
      "362 0.0003647323464974761\n",
      "363 0.000354454736225307\n",
      "364 0.0003444791946094483\n",
      "365 0.00033477164106443524\n",
      "366 0.00032534217461943626\n",
      "367 0.00031618616776540875\n",
      "368 0.0003072969848290086\n",
      "369 0.0002986597246490419\n",
      "370 0.0002902632695622742\n",
      "371 0.0002821112284436822\n",
      "372 0.0002741922507993877\n",
      "373 0.0002664962667040527\n",
      "374 0.0002590194344520569\n",
      "375 0.0002517578541301191\n",
      "376 0.0002447029110044241\n",
      "377 0.00023785322264302522\n",
      "378 0.00023118668468669057\n",
      "379 0.0002247207157779485\n",
      "380 0.0002184329932788387\n",
      "381 0.00021232242579571903\n",
      "382 0.00020638800924643874\n",
      "383 0.00020062379189766943\n",
      "384 0.00019501926726661623\n",
      "385 0.0001895724271889776\n",
      "386 0.00018428516341373324\n",
      "387 0.00017914632917381823\n",
      "388 0.00017415653564967215\n",
      "389 0.00016929888806771487\n",
      "390 0.0001645838638069108\n",
      "391 0.00015999827883206308\n",
      "392 0.0001555472263135016\n",
      "393 0.00015121638716664165\n",
      "394 0.00014701165491715074\n",
      "395 0.00014292169362306595\n",
      "396 0.00013895264419261366\n",
      "397 0.00013509496056940407\n",
      "398 0.0001313454849878326\n",
      "399 0.00012769701424986124\n",
      "400 0.00012415455421432853\n",
      "401 0.00012071094533894211\n",
      "402 0.00011736564920283854\n",
      "403 0.0001141126558650285\n",
      "404 0.00011095392255811021\n",
      "405 0.00010788057988975197\n",
      "406 0.00010489238775335252\n",
      "407 0.0001019897754304111\n",
      "408 9.917042189044878e-05\n",
      "409 9.642742952564731e-05\n",
      "410 9.376526577398181e-05\n",
      "411 9.117172157857567e-05\n",
      "412 8.865515701472759e-05\n",
      "413 8.62067099660635e-05\n",
      "414 8.382907253690064e-05\n",
      "415 8.151980000548065e-05\n",
      "416 7.927326078061014e-05\n",
      "417 7.708827615715563e-05\n",
      "418 7.496487523894757e-05\n",
      "419 7.289883797056973e-05\n",
      "420 7.089326390996575e-05\n",
      "421 6.894176476635039e-05\n",
      "422 6.704793486278504e-05\n",
      "423 6.520221359096467e-05\n",
      "424 6.341118569253013e-05\n",
      "425 6.166825914988294e-05\n",
      "426 5.997465632390231e-05\n",
      "427 5.83266191824805e-05\n",
      "428 5.672466068062931e-05\n",
      "429 5.51688572159037e-05\n",
      "430 5.3654934163205326e-05\n",
      "431 5.2185459935572e-05\n",
      "432 5.0754682888509706e-05\n",
      "433 4.936386540066451e-05\n",
      "434 4.801256727660075e-05\n",
      "435 4.669871486839838e-05\n",
      "436 4.5419103116728365e-05\n",
      "437 4.417612944962457e-05\n",
      "438 4.296741826692596e-05\n",
      "439 4.179155075689778e-05\n",
      "440 4.064955282956362e-05\n",
      "441 3.954038766096346e-05\n",
      "442 3.846146137220785e-05\n",
      "443 3.741082764463499e-05\n",
      "444 3.639059286797419e-05\n",
      "445 3.5397199098952115e-05\n",
      "446 3.443314926698804e-05\n",
      "447 3.3493626688141376e-05\n",
      "448 3.2581559935351834e-05\n",
      "449 3.1693154596723616e-05\n",
      "450 3.083068804698996e-05\n",
      "451 2.999228672706522e-05\n",
      "452 2.9174752853577957e-05\n",
      "453 2.8381393349263817e-05\n",
      "454 2.7609681637841277e-05\n",
      "455 2.6858380806515925e-05\n",
      "456 2.6128196623176336e-05\n",
      "457 2.5418657969566993e-05\n",
      "458 2.4728318749112077e-05\n",
      "459 2.4057710106717423e-05\n",
      "460 2.3404802050208673e-05\n",
      "461 2.2769014321966097e-05\n",
      "462 2.2152446035761386e-05\n",
      "463 2.1551446479861625e-05\n",
      "464 2.0966765077901073e-05\n",
      "465 2.0398856577230617e-05\n",
      "466 1.9846258510369807e-05\n",
      "467 1.9309725757921115e-05\n",
      "468 1.8786035070661455e-05\n",
      "469 1.827842424972914e-05\n",
      "470 1.778474688762799e-05\n",
      "471 1.7302776541328058e-05\n",
      "472 1.6835154383443296e-05\n",
      "473 1.6379952285205945e-05\n",
      "474 1.5937728676362894e-05\n",
      "475 1.5507423086091876e-05\n",
      "476 1.5088983673194889e-05\n",
      "477 1.4680578715342563e-05\n",
      "478 1.4285427823779173e-05\n",
      "479 1.389973931509303e-05\n",
      "480 1.3525448594009504e-05\n",
      "481 1.3161030437913723e-05\n",
      "482 1.2805205187760293e-05\n",
      "483 1.2460272955649998e-05\n",
      "484 1.212498864333611e-05\n",
      "485 1.1798932973761111e-05\n",
      "486 1.1481875844765455e-05\n",
      "487 1.1172262020409107e-05\n",
      "488 1.0871626727748662e-05\n",
      "489 1.0579578884062357e-05\n",
      "490 1.0295297215634491e-05\n",
      "491 1.001872806227766e-05\n",
      "492 9.749110176926479e-06\n",
      "493 9.488228897680528e-06\n",
      "494 9.233503078576177e-06\n",
      "495 8.985652129922528e-06\n",
      "496 8.74411671247799e-06\n",
      "497 8.509638064424507e-06\n",
      "498 8.281930604425725e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 8.05988565844018e-06\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "  \n",
    "   y_pred = model(x)\n",
    "            \n",
    " \n",
    "   loss = loss_fn(y_pred, y) # <=# Obliczenie i wydruku straty. Mijamy Tensory zawierające przewidywane i prawdziwe\n",
    "   print(t, loss.item())     # <=# wartości y, a funkcja straty zwraca Tensor zawierający stratę.\n",
    "       \n",
    "  \n",
    "   model.zero_grad()    #<= # Zeruj gradienty przed uruchomieniem przejścia do tyłu. \n",
    "   \n",
    "\n",
    "   loss.backward()      #<== Przełożenie wsteczne: oblicz gradient gradientu w odniesieniu do wszystkich możliwych do nauczenia się\n",
    "                                 # parametrów modelu. Wewnętrznie parametry każdego modułu są przechowywane\n",
    "                                 # w Tensorach z requires_grad=True, więc to wywołanie obliczy gradienty\n",
    "                                 # wszystkich możliwych do nauczenia parametrów w modelu.\n",
    "  \n",
    "   with torch.no_grad():              #<== Zaktualizuj ciężary za pomocą opadania gradientu. Każdy parametr jest tensorem, więc\n",
    "     for param in model.parameters():         # możemy uzyskać dostęp do jego danych i gradientów tak jak wcześniej.\n",
    "       param.data -= learning_rate * param.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
