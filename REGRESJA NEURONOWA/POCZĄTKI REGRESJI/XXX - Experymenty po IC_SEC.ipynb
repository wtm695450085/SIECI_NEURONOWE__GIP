{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 250%;color:#1155cc\"> XXX experymenty po IC_SEC\n",
    "\n",
    "<span style=\"font-size: 150%;color:Red\"> 26.07.2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp    datetime64[ns]\n",
      "Value                 int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-01 00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-01 00:00:10.000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-05-01 00:00:20.000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-05-01 00:00:29.985</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  Value\n",
       "0 2020-05-01 00:00:00.000      0\n",
       "1 2020-05-01 00:00:10.000     10\n",
       "2 2020-05-01 00:00:20.000     20\n",
       "3 2020-05-01 00:00:29.985     30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('/media/wojciech/D6DE33C1DE339927/1A/dane1.xlsx')    \n",
    "print(df.dtypes)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "\n",
    "df.columns = ['level_0', 'Count', 'Timestamp', 'Value']\n",
    "#del df['level_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>Count</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-01 00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-05-01 00:00:10.000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-05-01 00:00:20.000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-05-01 00:00:29.985</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-05-01 00:00:39.980</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  Count               Timestamp  Value\n",
       "0        0      0 2020-05-01 00:00:00.000      0\n",
       "1        1      1 2020-05-01 00:00:10.000     10\n",
       "2        2      2 2020-05-01 00:00:20.000     20\n",
       "3        3      3 2020-05-01 00:00:29.985     30\n",
       "4        4      4 2020-05-01 00:00:39.980     40"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TworzÄ™ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Count'] = df['Count'].astype(np.float32)\n",
    "x = df['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.],\n",
       "       [  1.],\n",
       "       [  2.],\n",
       "       [  3.],\n",
       "       [  4.],\n",
       "       [  5.],\n",
       "       [  6.],\n",
       "       [  7.],\n",
       "       [  8.],\n",
       "       [  9.],\n",
       "       [ 10.],\n",
       "       [ 11.],\n",
       "       [ 12.],\n",
       "       [ 13.],\n",
       "       [ 14.],\n",
       "       [ 15.],\n",
       "       [ 16.],\n",
       "       [ 17.],\n",
       "       [ 18.],\n",
       "       [ 19.],\n",
       "       [ 20.],\n",
       "       [ 21.],\n",
       "       [ 22.],\n",
       "       [ 23.],\n",
       "       [ 24.],\n",
       "       [ 25.],\n",
       "       [ 26.],\n",
       "       [ 27.],\n",
       "       [ 28.],\n",
       "       [ 29.],\n",
       "       [ 30.],\n",
       "       [ 31.],\n",
       "       [ 32.],\n",
       "       [ 33.],\n",
       "       [ 34.],\n",
       "       [ 35.],\n",
       "       [ 36.],\n",
       "       [ 37.],\n",
       "       [ 38.],\n",
       "       [ 39.],\n",
       "       [ 40.],\n",
       "       [ 41.],\n",
       "       [ 42.],\n",
       "       [ 43.],\n",
       "       [ 44.],\n",
       "       [ 45.],\n",
       "       [ 46.],\n",
       "       [ 47.],\n",
       "       [ 48.],\n",
       "       [ 49.],\n",
       "       [ 50.],\n",
       "       [ 51.],\n",
       "       [ 52.],\n",
       "       [ 53.],\n",
       "       [ 54.],\n",
       "       [ 55.],\n",
       "       [ 56.],\n",
       "       [ 57.],\n",
       "       [ 58.],\n",
       "       [ 59.],\n",
       "       [ 60.],\n",
       "       [ 61.],\n",
       "       [ 62.],\n",
       "       [ 63.],\n",
       "       [ 64.],\n",
       "       [ 65.],\n",
       "       [ 66.],\n",
       "       [ 67.],\n",
       "       [ 68.],\n",
       "       [ 69.],\n",
       "       [ 70.],\n",
       "       [ 71.],\n",
       "       [ 72.],\n",
       "       [ 73.],\n",
       "       [ 74.],\n",
       "       [ 75.],\n",
       "       [ 76.],\n",
       "       [ 77.],\n",
       "       [ 78.],\n",
       "       [ 79.],\n",
       "       [ 80.],\n",
       "       [ 81.],\n",
       "       [ 82.],\n",
       "       [ 83.],\n",
       "       [ 84.],\n",
       "       [ 85.],\n",
       "       [ 86.],\n",
       "       [ 87.],\n",
       "       [ 88.],\n",
       "       [ 89.],\n",
       "       [ 90.],\n",
       "       [ 91.],\n",
       "       [ 92.],\n",
       "       [ 93.],\n",
       "       [ 94.],\n",
       "       [ 95.],\n",
       "       [ 96.],\n",
       "       [ 97.],\n",
       "       [ 98.],\n",
       "       [ 99.],\n",
       "       [100.],\n",
       "       [101.],\n",
       "       [102.],\n",
       "       [103.],\n",
       "       [104.],\n",
       "       [105.],\n",
       "       [106.],\n",
       "       [107.],\n",
       "       [108.],\n",
       "       [109.],\n",
       "       [110.],\n",
       "       [111.],\n",
       "       [112.],\n",
       "       [113.],\n",
       "       [114.],\n",
       "       [115.],\n",
       "       [116.],\n",
       "       [117.],\n",
       "       [118.],\n",
       "       [119.],\n",
       "       [120.],\n",
       "       [121.],\n",
       "       [122.],\n",
       "       [123.],\n",
       "       [124.],\n",
       "       [125.],\n",
       "       [126.],\n",
       "       [127.],\n",
       "       [128.],\n",
       "       [129.],\n",
       "       [130.],\n",
       "       [131.],\n",
       "       [132.],\n",
       "       [133.],\n",
       "       [134.],\n",
       "       [135.],\n",
       "       [136.],\n",
       "       [137.],\n",
       "       [138.],\n",
       "       [139.],\n",
       "       [140.],\n",
       "       [141.],\n",
       "       [142.],\n",
       "       [143.],\n",
       "       [144.],\n",
       "       [145.],\n",
       "       [146.],\n",
       "       [147.],\n",
       "       [148.],\n",
       "       [149.],\n",
       "       [150.],\n",
       "       [151.],\n",
       "       [152.],\n",
       "       [153.],\n",
       "       [154.],\n",
       "       [155.],\n",
       "       [156.],\n",
       "       [157.],\n",
       "       [158.],\n",
       "       [159.],\n",
       "       [160.],\n",
       "       [161.],\n",
       "       [162.],\n",
       "       [163.],\n",
       "       [164.],\n",
       "       [165.],\n",
       "       [166.],\n",
       "       [167.],\n",
       "       [168.],\n",
       "       [169.],\n",
       "       [170.],\n",
       "       [171.],\n",
       "       [172.],\n",
       "       [173.],\n",
       "       [174.],\n",
       "       [175.],\n",
       "       [176.],\n",
       "       [177.],\n",
       "       [178.],\n",
       "       [179.],\n",
       "       [180.],\n",
       "       [181.],\n",
       "       [182.],\n",
       "       [183.],\n",
       "       [184.],\n",
       "       [185.],\n",
       "       [186.],\n",
       "       [187.],\n",
       "       [188.],\n",
       "       [189.],\n",
       "       [190.],\n",
       "       [191.],\n",
       "       [192.],\n",
       "       [193.],\n",
       "       [194.],\n",
       "       [195.],\n",
       "       [196.],\n",
       "       [197.],\n",
       "       [198.],\n",
       "       [199.],\n",
       "       [200.],\n",
       "       [201.],\n",
       "       [202.],\n",
       "       [203.],\n",
       "       [204.],\n",
       "       [205.],\n",
       "       [206.],\n",
       "       [207.],\n",
       "       [208.],\n",
       "       [209.],\n",
       "       [210.],\n",
       "       [211.],\n",
       "       [212.],\n",
       "       [213.],\n",
       "       [214.],\n",
       "       [215.],\n",
       "       [216.],\n",
       "       [217.],\n",
       "       [218.],\n",
       "       [219.],\n",
       "       [220.],\n",
       "       [221.],\n",
       "       [222.],\n",
       "       [223.],\n",
       "       [224.],\n",
       "       [225.],\n",
       "       [226.],\n",
       "       [227.],\n",
       "       [228.],\n",
       "       [229.],\n",
       "       [230.],\n",
       "       [231.],\n",
       "       [232.],\n",
       "       [233.],\n",
       "       [234.],\n",
       "       [235.],\n",
       "       [236.],\n",
       "       [237.],\n",
       "       [238.],\n",
       "       [239.],\n",
       "       [240.],\n",
       "       [241.],\n",
       "       [242.],\n",
       "       [243.],\n",
       "       [244.],\n",
       "       [245.],\n",
       "       [246.],\n",
       "       [247.],\n",
       "       [248.],\n",
       "       [249.],\n",
       "       [250.],\n",
       "       [251.],\n",
       "       [252.],\n",
       "       [253.],\n",
       "       [254.],\n",
       "       [255.],\n",
       "       [256.],\n",
       "       [257.],\n",
       "       [258.],\n",
       "       [259.],\n",
       "       [260.],\n",
       "       [261.],\n",
       "       [262.],\n",
       "       [263.],\n",
       "       [264.],\n",
       "       [265.],\n",
       "       [266.],\n",
       "       [267.],\n",
       "       [268.],\n",
       "       [269.],\n",
       "       [270.],\n",
       "       [271.],\n",
       "       [272.],\n",
       "       [273.],\n",
       "       [274.],\n",
       "       [275.],\n",
       "       [276.],\n",
       "       [277.],\n",
       "       [278.],\n",
       "       [279.],\n",
       "       [280.],\n",
       "       [281.],\n",
       "       [282.],\n",
       "       [283.],\n",
       "       [284.],\n",
       "       [285.],\n",
       "       [286.],\n",
       "       [287.],\n",
       "       [288.],\n",
       "       [289.],\n",
       "       [290.],\n",
       "       [291.],\n",
       "       [292.],\n",
       "       [293.],\n",
       "       [294.],\n",
       "       [295.],\n",
       "       [296.],\n",
       "       [297.],\n",
       "       [298.],\n",
       "       [299.],\n",
       "       [300.],\n",
       "       [301.],\n",
       "       [302.],\n",
       "       [303.],\n",
       "       [304.],\n",
       "       [305.],\n",
       "       [306.],\n",
       "       [307.],\n",
       "       [308.],\n",
       "       [309.],\n",
       "       [310.],\n",
       "       [311.],\n",
       "       [312.],\n",
       "       [313.],\n",
       "       [314.],\n",
       "       [315.],\n",
       "       [316.],\n",
       "       [317.],\n",
       "       [318.],\n",
       "       [319.],\n",
       "       [320.],\n",
       "       [321.],\n",
       "       [322.],\n",
       "       [323.],\n",
       "       [324.],\n",
       "       [325.],\n",
       "       [326.],\n",
       "       [327.],\n",
       "       [328.],\n",
       "       [329.],\n",
       "       [330.],\n",
       "       [331.],\n",
       "       [332.],\n",
       "       [333.],\n",
       "       [334.],\n",
       "       [335.],\n",
       "       [336.],\n",
       "       [337.],\n",
       "       [338.],\n",
       "       [339.],\n",
       "       [340.],\n",
       "       [341.],\n",
       "       [342.],\n",
       "       [343.],\n",
       "       [344.],\n",
       "       [345.],\n",
       "       [346.],\n",
       "       [347.],\n",
       "       [348.],\n",
       "       [349.],\n",
       "       [350.],\n",
       "       [351.],\n",
       "       [352.],\n",
       "       [353.],\n",
       "       [354.],\n",
       "       [355.],\n",
       "       [356.],\n",
       "       [357.],\n",
       "       [358.],\n",
       "       [359.],\n",
       "       [360.],\n",
       "       [361.],\n",
       "       [362.],\n",
       "       [363.],\n",
       "       [364.],\n",
       "       [365.],\n",
       "       [366.],\n",
       "       [367.],\n",
       "       [368.],\n",
       "       [369.],\n",
       "       [370.],\n",
       "       [371.],\n",
       "       [372.],\n",
       "       [373.],\n",
       "       [374.],\n",
       "       [375.],\n",
       "       [376.],\n",
       "       [377.],\n",
       "       [378.],\n",
       "       [379.],\n",
       "       [380.],\n",
       "       [381.],\n",
       "       [382.],\n",
       "       [383.],\n",
       "       [384.],\n",
       "       [385.],\n",
       "       [386.],\n",
       "       [387.],\n",
       "       [388.],\n",
       "       [389.],\n",
       "       [390.],\n",
       "       [391.],\n",
       "       [392.],\n",
       "       [393.],\n",
       "       [394.],\n",
       "       [395.],\n",
       "       [396.],\n",
       "       [397.],\n",
       "       [398.],\n",
       "       [399.],\n",
       "       [400.],\n",
       "       [401.],\n",
       "       [402.],\n",
       "       [403.],\n",
       "       [404.],\n",
       "       [405.],\n",
       "       [406.],\n",
       "       [407.],\n",
       "       [408.],\n",
       "       [409.],\n",
       "       [410.],\n",
       "       [411.],\n",
       "       [412.],\n",
       "       [413.],\n",
       "       [414.],\n",
       "       [415.],\n",
       "       [416.],\n",
       "       [417.],\n",
       "       [418.],\n",
       "       [419.],\n",
       "       [420.],\n",
       "       [421.],\n",
       "       [422.],\n",
       "       [423.],\n",
       "       [424.],\n",
       "       [425.],\n",
       "       [426.],\n",
       "       [427.],\n",
       "       [428.],\n",
       "       [429.],\n",
       "       [430.],\n",
       "       [431.],\n",
       "       [432.],\n",
       "       [433.],\n",
       "       [434.],\n",
       "       [435.],\n",
       "       [436.],\n",
       "       [437.],\n",
       "       [438.],\n",
       "       [439.],\n",
       "       [440.],\n",
       "       [441.],\n",
       "       [442.],\n",
       "       [443.],\n",
       "       [444.],\n",
       "       [445.],\n",
       "       [446.],\n",
       "       [447.],\n",
       "       [448.],\n",
       "       [449.],\n",
       "       [450.],\n",
       "       [451.],\n",
       "       [452.],\n",
       "       [453.],\n",
       "       [454.],\n",
       "       [455.],\n",
       "       [456.],\n",
       "       [457.],\n",
       "       [458.],\n",
       "       [459.],\n",
       "       [460.],\n",
       "       [461.],\n",
       "       [462.],\n",
       "       [463.],\n",
       "       [464.],\n",
       "       [465.],\n",
       "       [466.],\n",
       "       [467.],\n",
       "       [468.],\n",
       "       [469.],\n",
       "       [470.],\n",
       "       [471.],\n",
       "       [472.],\n",
       "       [473.],\n",
       "       [474.],\n",
       "       [475.],\n",
       "       [476.],\n",
       "       [477.],\n",
       "       [478.],\n",
       "       [479.],\n",
       "       [480.],\n",
       "       [481.],\n",
       "       [482.],\n",
       "       [483.],\n",
       "       [484.],\n",
       "       [485.],\n",
       "       [486.],\n",
       "       [487.],\n",
       "       [488.],\n",
       "       [489.],\n",
       "       [490.],\n",
       "       [491.],\n",
       "       [492.],\n",
       "       [493.],\n",
       "       [494.],\n",
       "       [495.],\n",
       "       [496.],\n",
       "       [497.],\n",
       "       [498.],\n",
       "       [499.],\n",
       "       [500.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.values\n",
    "x.reshape(501,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### robiÄ™ standaryzacjÄ™ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195.\n 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209.\n 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223.\n 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237.\n 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251.\n 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265.\n 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279.\n 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293.\n 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307.\n 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321.\n 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335.\n 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349.\n 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363.\n 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377.\n 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391.\n 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405.\n 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419.\n 420. 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433.\n 434. 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447.\n 448. 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461.\n 462. 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475.\n 476. 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489.\n 490. 491. 492. 493. 494. 495. 496. 497. 498. 499. 500.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-591259b9fe5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    696\u001b[0m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[1;32m    697\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m                                 force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    622\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.\n  14.  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.\n  28.  29.  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.\n  42.  43.  44.  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.\n  56.  57.  58.  59.  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.\n  70.  71.  72.  73.  74.  75.  76.  77.  78.  79.  80.  81.  82.  83.\n  84.  85.  86.  87.  88.  89.  90.  91.  92.  93.  94.  95.  96.  97.\n  98.  99. 100. 101. 102. 103. 104. 105. 106. 107. 108. 109. 110. 111.\n 112. 113. 114. 115. 116. 117. 118. 119. 120. 121. 122. 123. 124. 125.\n 126. 127. 128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139.\n 140. 141. 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153.\n 154. 155. 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167.\n 168. 169. 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181.\n 182. 183. 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195.\n 196. 197. 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209.\n 210. 211. 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223.\n 224. 225. 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237.\n 238. 239. 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251.\n 252. 253. 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265.\n 266. 267. 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279.\n 280. 281. 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293.\n 294. 295. 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307.\n 308. 309. 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321.\n 322. 323. 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335.\n 336. 337. 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349.\n 350. 351. 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363.\n 364. 365. 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377.\n 378. 379. 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391.\n 392. 393. 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405.\n 406. 407. 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419.\n 420. 421. 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433.\n 434. 435. 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447.\n 448. 449. 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461.\n 462. 463. 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475.\n 476. 477. 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489.\n 490. 491. 492. 493. 494. 495. 496. 497. 498. 499. 500.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)\n",
    "\n",
    "print(np.round(x.std(), decimals=2), np.round(x.mean(), decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.astype(np.float32)\n",
    "x = torch.tensor(x)\n",
    "x = x.reshape(501,1)\n",
    "print(x[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Value'] = df['Value'].astype(np.float32)\n",
    "y = df['Value'].values \n",
    "y = torch.tensor(y)\n",
    "print(y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(501,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "y = sc.fit_transform(y)\n",
    "\n",
    "print(np.round(y.std(), decimals=2), np.round(y.mean(), decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 1. Tworzenie zbioru danych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "#x = torch.unsqueeze(torch.linspace(-10, 10, 100), dim=1)  # x data (tensor), shape=(100, 1)\n",
    "#y = torch.cos(x) + 0.5*torch.rand(x.size())                # noisy y data (tensor), shape=(100, 1)\n",
    "\n",
    "# torch can only train on Variable, so convert them to Variable\n",
    "x, y = Variable(x), Variable(y)\n",
    "\n",
    "# view data\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.scatter(x.data.numpy(), y.data.numpy(), color = \"blue\")\n",
    "plt.title('Regression Analysis')\n",
    "plt.xlabel('Independent varible')\n",
    "plt.ylabel('Dependent varible')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 2. Definiowanie sieci neuronowej\n",
    "##### 2.1 Programowanie torch.nn.Module"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Definicja krztaÅ‚tu sieci\n",
    "Ta sieÄ‡ ma tylko jednÄ… ukrytÄ… warstwÄ™, ale teraz ma 150 wÄ™zÅ‚Ã³w, a po nim nastÄ™puje funkcja LeakyReLu.\n",
    "Musi byc jedna zmienna wejÅ›ciowa i jedna wartoÅ›Ä‡ wynikowa Å¼eby byÅ‚y takie fajne wykresy dwÃ³wymiarowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "        torch.nn.Linear(1, 150),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(150, 100),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Linear(100, 1),\n",
    "    )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Algorytm optymalizacji: \n",
    "\n",
    "##### Optymalizator SGD\n",
    "lr: SzybkoÅ›Ä‡ uczenia siÄ™ -> SzybkoÅ›Ä‡, z jakÄ… nasz model aktualizuje wagi w komÃ³rkach za kaÅ¼dym razem, gdy przeprowadzana jest wsteczna propagacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optymalizator ADAM \n",
    "zamiast uÅ¼ytego optymalizatora SGD, dziaÅ‚a lepiej dla powykrÄ™canego zbioru danych empirycznych. NaleÅ¼y przetestowaÄ‡ rÃ³Å¼ne rodzaje optymalizatorÃ³w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optymalizator ADAMMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.Adamax(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optymalizator ASGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.ASGD(net.parameters(), lr=0.01, lambd=0.0001, alpha=0.15, t0=000000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.LBFGS(net.parameters(), lr=0.01, max_iter=20, max_eval=None, tolerance_grad=1e-05, tolerance_change=1e-09, history_size=100, line_search_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bardzo dobre efekty daje optimizer RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.RMSprop(net.parameters(), lr=0.01, alpha=0.99, eps=1e-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DoskonaÅ‚Ä™ efekty daje optimizer RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.Rprop(net.parameters(), lr=0.01, etas=(0.5, 1.2), step_sizes=(1e-06, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0, dampening=0, weight_decay=0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Definicja funkcji straty\n",
    "to jest R2 dla regresji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 3. Definiowanie procesu nauki i nauka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Variable(x)                          #1. deklarujemy x i y do nauki\n",
    "outputs = Variable(y)\n",
    "for i in range(4050):                          #2. pÄ™tla 1050 powtÃ³rzeÅ„ (epok)\n",
    "   prediction = net(inputs)\n",
    "   loss = loss_func(prediction, outputs) \n",
    "   optimizer.zero_grad()\n",
    "   loss.backward()        \n",
    "   optimizer.step()       \n",
    "\n",
    "   if i % 200 == 0:                             #3. Pokazuje naukÄ™ co 100 krokÃ³w\n",
    "       # plot and show learning process\n",
    "       plt.cla()\n",
    "       plt.scatter(x.data.numpy(), y.data.numpy())\n",
    "       plt.plot(x.data.numpy(), prediction.data.numpy(), 'r--', lw=2)\n",
    "       plt.text(0.65, 0.1, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 10, 'color':  'black'})\n",
    "       plt.text(0.65, 0.3, 'step = %d' % i, fontdict={'size': 10, 'color':  'black'})\n",
    "       plt.pause(0.1)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
